{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818458ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp esploco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6f7fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48011326",
   "metadata": {},
   "source": [
    "# esploco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ee297d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\"\"\"\n",
    "Created on Wed Mar 18 17:59:42 2020\n",
    "@author: Sanguyu Xu\n",
    "xusangyu@gmail.com\n",
    "\"\"\"\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from esploco import locoDataMunger\n",
    "from esploco import locoUtilities\n",
    "from esploco import locoPlotters\n",
    "from esploco import plotTools as pt\n",
    "import dabest\n",
    "from esploco.plotTools import setFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c45b905",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class esploco(object):\n",
    "    \n",
    "    \"\"\"\n",
    "    Class for calculating and plotting espresso locomotion data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataFolder, startMin = 0, endMin = 120, companionEspObj=None, initialResamplePeriod=50, smoothing=True, longForm=False):\n",
    "        \"\"\"\n",
    "\n",
    "        Reads and stores information from countLogs produced by Critta espresso plugin\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        dataFolder : str\n",
    "            path to the directory containing all output files of espresso assay\n",
    "        startMin : int, default 0\n",
    "            starting minute for analysis\n",
    "        endMin: int, default 120\n",
    "        companionEspObj: an espresso object, default None\n",
    "            from the espresso analysis package\n",
    "        initialResamplePeriod: int, default 50\n",
    "        smoothing: boolean, default True\n",
    "            whether or not to smooth the trajectories\n",
    "        longForm: boolean, default False\n",
    "            whether or not the data input is the same set of flies but over many days.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        An `esploco` object.\n",
    "        `esploco.resultsDf` contains relevant output metrics \n",
    "        '.ID': from metadata\n",
    "        '.Status': 'Test' or 'Ctrl'\n",
    "        '.Genotype': genotype\n",
    "        '.Sex': from metadata\n",
    "        '.MinimumAge': from metadata\n",
    "        '.MaximumAge': from metadata \n",
    "        '.Food1': from metadata\n",
    "        '.Food2': from metadata \n",
    "        '.Temperature': from metadata \n",
    "        '.#Flies': from metadata \n",
    "        '.Starvedhrs': from metadata \n",
    "        '.Date': date of feedlog\n",
    "        '.averageSpeed_mm/s': instantaneous speed of the fly \n",
    "        '.xPosition_mm': instantaneous x position of the fly \n",
    "        '.yPosition_mm': instantaneous y position of the fly \n",
    "        '.inLeftPort': proportion of time the fly was in left port\n",
    "        '.inRightPort': proportion of time the fly was in right port \n",
    "        '.countLogDate': date from countlog\n",
    "        '.feedLogDate': date from feedlog\n",
    "           \n",
    "        \"\"\"\n",
    "        \n",
    "        self.cm = 1/2.54\n",
    "        if dataFolder[-1] != '/':\n",
    "            dataFolder = dataFolder+'/'\n",
    "        self.metaDataDf, self.countLogDf, self.portLocationsDf, self.experimentSummary = locoDataMunger.readMetaAndCount(\n",
    "            dataFolder, companionEspObj, startMin, endMin, initialResamplePeriod, smoothing, longForm)\n",
    "        print(self.metaDataDf)\n",
    "        print(self.countLogDf)\n",
    "        print(self.portLocationsDf)\n",
    "        print(self.experimentSummary)\n",
    "        outputDir = locoUtilities.makeOutputFolders(dataFolder)\n",
    "        self.dataFolder = dataFolder\n",
    "        self.outputFolder = outputDir\n",
    "        self.startMin = startMin\n",
    "        self.endMin = endMin\n",
    "        self.resultsDf = self.metaDataDf\n",
    "        self.resultsDf['averageSpeed_mm/s'] = np.nanmean(\n",
    "            self.countLogDf.filter(regex='_V'), axis=0)\n",
    "        self.resultsDf['xPosition_mm'] = np.nanmean(\n",
    "            self.countLogDf.filter(regex='_X'), axis=0)\n",
    "        self.resultsDf['yPosition_mm'] = np.nanmean(\n",
    "            self.countLogDf.filter(regex='_Y'), axis=0)\n",
    "        self.resultsDf['inLeftPort'] = np.nanmean(\n",
    "            100*(self.countLogDf.filter(regex='LeftPort') > 0), axis=0)\n",
    "        self.resultsDf['inRightPort'] = np.nanmean(\n",
    "            100*(self.countLogDf.filter(regex='RightPort') > 0), axis=0)\n",
    "        print(self.resultsDf)\n",
    "        if any(self.experimentSummary.countLogDate.str.contains(self.resultsDf.Date[0])):\n",
    "            self.resultsDf['countLogDate'] = self.resultsDf['Date']\n",
    "            self.resultsDf['feedLogDate'] = [self.experimentSummary.loc[self.experimentSummary['countLogDate']\n",
    "                                                                        == d]['feedLogDate'].iloc[0] for d in self.resultsDf['Date']]\n",
    "        else:\n",
    "            self.resultsDf['feedLogDate'] = self.resultsDf['Date']\n",
    "            self.resultsDf['countLogDate'] = [self.experimentSummary.loc[self.experimentSummary['feedLogDate']\n",
    "                                                                         == d]['countLogDate'].iloc[0] for d in self.resultsDf['Date']]\n",
    "#     show_doc(__init__)\n",
    "    def versionNotes(self):\n",
    "        print('version notes 0.1.1: added portlocations')\n",
    "        print('version notes 0.1.2: added gaussian smoothing of x y locations')\n",
    "        print('version notes 0.1.3: added detection of fall events')\n",
    "        print('version notes 0.1.4: bugfix setfont and moved colorbar on heatmap to bottom')\n",
    "        print('version notes 0.1.5: added handling of dabest 0.3.9999')\n",
    "        print('version notes 0.2.0: major refactoring')\n",
    "        print('version notes 23.04.21: nbdev')\n",
    "\n",
    " \n",
    "    def plotChamberSmallMultiples(self, ncol=15, customPalette=None, setNumber=None):\n",
    "        \"\"\"\n",
    "\n",
    "        Plots trajectories and or heatmaps in the arrangement of the chambers for each dataset\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        ncol : int, default 15\n",
    "            number of columns for the plots\n",
    "        customPalette : dict, default None\n",
    "            user can supply a dict for use as a custom palette\n",
    "        setNumber: int, default None\n",
    "            user specfied set to plot\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        An `chamberSmallsTrack` figure object and an `chamberSmallsHeat` figure object.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        dates = self.metaDataDf.Date.unique()\n",
    "        chamberSmallsTrack = np.empty(len(dates), dtype=object)\n",
    "        axarrT = np.empty(len(dates), dtype=object)\n",
    "        chamberSmallsHeat = np.empty(len(dates), dtype=object)\n",
    "        axarrH = np.empty(len(dates), dtype=object)\n",
    "        print('Espresso Runs found:\\n')\n",
    "        print(dates)\n",
    "        if setNumber is not None:\n",
    "            dates = [dates[setNumber]]\n",
    "        for i in range(0, len(dates)):\n",
    "            print('\\n\\n plotting ' + dates[i] + '...')\n",
    "            portFile = self.experimentSummary.loc[self.experimentSummary['metaDataFile']\n",
    "                                                  == 'MetaData_'+dates[i] + '.csv']['portLocationsFile'].iloc[0]\n",
    "            portDate = locoDataMunger.extractDateStr(portFile)[0]\n",
    "            submeta = self.metaDataDf.loc[self.metaDataDf.Date == dates[i]]\n",
    "            subcount = self.countLogDf.filter(regex=dates[i])\n",
    "            subport = self.portLocationsDf.loc[self.portLocationsDf.Date == portDate]\n",
    "            chamberSmallsTrack[i] = locoPlotters.putThingsInToChamberSubplot(\n",
    "                subcount, submeta, subport, customPalette, ncol)\n",
    "            chamberSmallsHeat[i] = locoPlotters.putThingsInToChamberSubplot(\n",
    "                subcount, submeta, subport, customPalette, ncol, locoPlotters.espressoPlotHeatmap)\n",
    "            outputDir = self.outputFolder + 'chamberPlots/'\n",
    "            locoUtilities.espressoSaveFig(\n",
    "                chamberSmallsTrack[i], 'chamberSmallsTrack', dates[i], outputDir, pngDPI=200)\n",
    "            locoUtilities.espressoSaveFig(\n",
    "                chamberSmallsHeat[i], 'chamberSmallsHeat', dates[i], outputDir, pngDPI=200)\n",
    "        self.chamberSmallsTrack = chamberSmallsTrack\n",
    "        self.chamberSmallsHeat = chamberSmallsHeat\n",
    "        return chamberSmallsTrack, chamberSmallsHeat\n",
    "#     show_doc(plotChamberSmallMultiples)\n",
    "    \n",
    "    def plotMeanHeatMaps(self, binSize=0.2, row=None, col=None, reverseRows=False, reverseCols=False, \n",
    "                         verbose=False, heatmapCMap='RdYlBu_r', smooth=2):\n",
    "        \"\"\"\n",
    "\n",
    "        Plots heatmap of mean duration stayed at each location throughout the chamber grouped by criteria\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        binSize : int, default 0.2\n",
    "            the size of the pixel in the heatmap\n",
    "        row : str, default None\n",
    "            a column name or independent variable to use for grouping the rows\n",
    "        col : str, default None\n",
    "            a column name or independent variable to use for grouping the columns\n",
    "        reverseRows : boolean, default False\n",
    "            to reverse the order of the rows \n",
    "        reverseCols : boolean, default False\n",
    "            to reverse the order of the columns \n",
    "        verbose : boolean, defult False\n",
    "            to produce output\n",
    "        heatmapCMap : cmap, default 'RdYlBu_r'\n",
    "            colormap used for the heatmap\n",
    "        smooth : int, default 2\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        `meanHeatmapFig`:  figure object\n",
    "        `Hall` : heatmap matrix.\n",
    "        `images` : \n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        heatMapOutputDir = self.outputFolder\n",
    "        if verbose:\n",
    "            meanHeatmapFig,  Hall, images, smallHeatmapFigs = locoPlotters.espressoPlotMeanHeatmaps(\n",
    "                self, binSize, None, None, False, False, verbose, heatmapCMap, smooth)\n",
    "            locoUtilities.espressoSaveFig(\n",
    "                smallHeatmapFigs, 'smallHeatmapFigs', self.metaDataDf.Date[0], heatMapOutputDir, pngDPI=200)\n",
    "        else:\n",
    "            meanHeatmapFig, Hall, images = locoPlotters.espressoPlotMeanHeatmaps(\n",
    "                self, binSize, row, col, reverseRows, reverseCols, verbose, heatmapCMap, smooth)\n",
    "        # self.resultsDf = resultsDf\n",
    "        self.heatmapMatrix = Hall\n",
    "        self.meanHeatmapFig = meanHeatmapFig\n",
    "        self.heatmapImages = images\n",
    "    \n",
    "#     show_doc(plotMeanHeatMaps)\n",
    "    \n",
    "    def plotBoundedLines(self,  colorBy, locoSuffix='V', row=None, col=None, rp='300s', YLim=[], customPalette={}, reverseRows=False,\n",
    "                         reverseCol=False, xUnit='min'):\n",
    "        \"\"\"\n",
    "\n",
    "        Plots ribbon plots of time series data such as speed, y-position, x-position, proportion of time in left port and right port\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        colorBy : str\n",
    "            column name for coloring the plots by\n",
    "        locoSuffix : str, default 'V'\n",
    "            'V': Speed of the fly, Y label is 'Average Speed (mm/s)', \n",
    "            'X': X position of the fly, Y label is 'X Position (mm)', \n",
    "            'Y': Y position of the fly, Y label is 'Y Position (mm)',\n",
    "            'InLeftPort': 'Percent time in Left Port',  \n",
    "            'InRightPort': 'Percent time in Right Port'\n",
    "        row : str, default None\n",
    "            a column name or independent variable to use for grouping the rows\n",
    "        col : str, default None\n",
    "            a column name or independent variable to use for grouping the columns\n",
    "        rp : str, default '300s'\n",
    "            resample rate\n",
    "        YLim : list, default []\n",
    "            custom y-lim for the plot\n",
    "        customPalette : str, default None\n",
    "            a column name or independent variable to use for grouping the columns             \n",
    "        reverseRows : boolean, default False\n",
    "            to reverse the order of the rows \n",
    "        reverseCols : boolean, default False\n",
    "            to reverse the order of the columns \n",
    "        xUnit : str, defult 's'\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        `figure`:  figure object\n",
    "\n",
    "        `axes` : axes handle for the axes\n",
    "        `meanLines` : array of values that are the plotted meanlines\n",
    "        `ciBounds` : array of values that are the plotted ci \n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        if xUnit == 'hour':\n",
    "            T = self.countLogDf.iloc[:, 0]/3600\n",
    "        else:\n",
    "            T = self.countLogDf.iloc[:, 0]/60\n",
    "\n",
    "        if 'Port' in locoSuffix:\n",
    "            metric = 100*(self.countLogDf.filter(regex='_' + locoSuffix) > 0)\n",
    "        else:\n",
    "            metric = self.countLogDf.filter(regex='_' + locoSuffix)\n",
    "\n",
    "        listOfPlots, gp, cPalette = locoPlotters.subplotRowColColor(\n",
    "            self.metaDataDf, colorBy, row, col, reverseRows, reverseCol)\n",
    "        if customPalette:\n",
    "            cPalette = customPalette\n",
    "        nr, nc = listOfPlots[-1][0][0:2]\n",
    "        figure, axes = plt.subplots(\n",
    "            nrows=nr + 1, ncols=nc + 1, squeeze=False, figsize=(3 * (nc + 1), 3 * (nr + 1)))\n",
    "        plotNames = [0]*len(listOfPlots)\n",
    "        meanLines = [0]*len(listOfPlots)\n",
    "        ciBounds = [0]*len(listOfPlots)\n",
    "\n",
    "        yl = {'V': 'Average Speed (mm/s)', 'X': 'X Position (mm)', 'Y': 'Y Position (mm)',\n",
    "              'InLeftPort': 'Percent time in Left Port',  'InRightPort': 'Percent time in Right Port'}\n",
    "        for i in range(0, len(listOfPlots)):\n",
    "            # print(listOfPlots[i])\n",
    "            ro, co = listOfPlots[i][0][0:2]\n",
    "            name = listOfPlots[i][1]\n",
    "            ind = gp[name]\n",
    "            locoPlotters.plotBoundedLine(\n",
    "                T, metric.iloc[:, ind], ax=axes[ro, co], c=cPalette[name[-1]], resamplePeriod=rp)\n",
    "            meanLines[i] = axes[ro, co].meanLine[0]\n",
    "            ciBounds[i] = axes[ro, co].ciBound\n",
    "            if co == 0:\n",
    "                axes[ro, co].set_ylabel(yl[locoSuffix])\n",
    "            if ro == axes.shape[0]:\n",
    "                axes[ro, co].set_xlabel('Time (hour)')\n",
    "            axes[ro, co].set_title(name[0] + ' ' + name[1])\n",
    "            axes[ro, co]. spines[\"right\"].set_visible(False)\n",
    "            axes[ro, co]. spines[\"top\"].set_visible(False)\n",
    "            plotNames[i] = name[-1]\n",
    "        ylims = [ax.get_ylim() for ax in axes.flatten()]\n",
    "        for i in range(0, len(listOfPlots)):\n",
    "            ro, co = listOfPlots[i][0][0:2]\n",
    "            if len(YLim) > 0:\n",
    "                axes[ro, co].set_ylim(YLim)\n",
    "            else:\n",
    "                axes[ro, co].set_ylim([np.min(ylims), np.max(ylims)])\n",
    "            locoPlotters.setAxesTicks(axes[ro, co], True, gridState=False)\n",
    "\n",
    "        axes[ro, co].legend(plotNames, loc='upper right', fontsize = 10)\n",
    "\n",
    "        locoUtilities.espressoSaveFig(\n",
    "            figure, 'boundedTS_' + locoSuffix + '_', self.metaDataDf.Date[0], self.outputFolder)\n",
    "\n",
    "        return figure, axes, meanLines, ciBounds\n",
    "#     show_doc(plotBoundedLines)\n",
    "\n",
    "    def calculatePeriFeedSpeed(self, companionEspObj, monitorWindow=120, startSeconds=0, plotDiagonal = True, plotContrast = True):\n",
    "        \"\"\"\n",
    "\n",
    "        Calculates speed of the fly around a feed\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        companionEspObj: an espresso object, default None\n",
    "                from the espresso analysis package\n",
    "\n",
    "        monitorWindow : int, in seconds, default 120\n",
    "            size of the window before and after the feed to monitor speed in\n",
    "        startSeconds : int, default 0 seconds\n",
    "            lower range of data to analyse\n",
    "        plotDiagonal : boolean, default True\n",
    "            whether or not to plot the diagonal speed plot \n",
    "        plotContrast : boolean, default True\n",
    "            whether or not to plot the contrast plots \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        `esploco.feedsRevisedDf`:  pandas dataframe that contains individual feeds and info about them in a time series\n",
    "        `esploco.resultsDf` : updated to contain information about feed and perifeed metrics\n",
    "        'ChamberID': from feedlog metadata\n",
    "        'Starved hrs': from feedlog metadata \n",
    "        'MealSizePerFly_µL': mean volume per meal per fly in µL\n",
    "        'AverageFeedSpeedPerFly_µl/s': mean feed speed per fly over all µL/s\n",
    "        'MeanSpeed120sBeforeFeed_mm/s': mean speed before feed mm/s\n",
    "        'MeanSpeedDuringFeed_mm/s': mean speed during feed mm/s \n",
    "        'MeanSpeed120sAfterFeed_mm/s': mean speed 120s after feed mm/s\n",
    "        'MeanMealDurationPerFly_s': mean meal duration per fly s \n",
    "        'Tube1': food in Tube 1\n",
    "        'AverageFeedVolumePerFly_µl': total volume per fly µL \n",
    "        'AverageFeedCountPerFly': total count per fly\n",
    "        'AverageFeedDurationPerFly_min': total feed duration per fly\n",
    "        'FeedVol_pl': total feed volume in pico liter\n",
    "        'Latency_min': latency to first feed in min\n",
    "        'duringBeforeSpeedRatio': ratio between during feed speed and before feed speed \n",
    "        'afterBeforeSpeedRatio': ratio between after feed speed and before feed speed\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        self.feedsRevisedDf, self.countLogDf, self.meanPeriSpeed, self.maxSpeed= locoDataMunger.calculatePeriFeedLoco(\n",
    "            self.countLogDf, self.portLocationsDf, companionEspObj, self.experimentSummary, monitorWindow, startSeconds)\n",
    "        self.resultsDf['ChamberID'] = self.resultsDf['feedLogDate'] + '_Chamber' + self.resultsDf['ID'].astype(str)\n",
    "        nonFeeders = list(set(self.resultsDf.ChamberID.unique())-set(self.feedsRevisedDf.ChamberID.unique()))\n",
    "        nonFeederDf = self.resultsDf.loc[self.resultsDf['ChamberID'].isin(nonFeeders)][['ChamberID', 'Genotype', 'Temperature', 'Status']]\n",
    "        self.feedsRevisedDf = pd.merge(self.feedsRevisedDf, nonFeederDf, how = 'outer', on = ['ChamberID', 'Genotype', 'Temperature', 'Status'])\n",
    "        self.feedsRevisedDf['FeedVol_pl'] = self.feedsRevisedDf['FeedVol_nl']*1000\n",
    "        if 'MeanSpeed'+str(monitorWindow)+'sBeforeFeed_mm/s' in self.resultsDf.columns:\n",
    "            self.resultsDf[['ChamberID', 'MeanSpeed'+str(monitorWindow)+'sBeforeFeed_mm/s', \n",
    "                            'MeanSpeedDuringFeed_mm/s','MeanSpeed'+str(monitorWindow)+'sAfterFeed_mm/s']] = self.meanPeriSpeed[['ChamberID', 'MeanSpeed'+str(monitorWindow)+'sBeforeFeed_mm/s', \n",
    "                                                                                  'MeanSpeedDuringFeed_mm/s',  'MeanSpeed'+str(monitorWindow)+'sAfterFeed_mm/s']]\n",
    "        else:\n",
    "            self.resultsDf = pd.merge(self.meanPeriSpeed, self.resultsDf, how=\"outer\", on='ChamberID')\n",
    "        for s in ['AverageFeedVolumePerFly_µl', 'MealSizePerFly_µL', 'AverageFeedCountPerFly',\n",
    "                 'MeanMealDurationPerFly_s', 'AverageFeedDurationPerFly_min', 'AverageFeedSpeedPerFly_µl/s',\n",
    "                 ]:\n",
    "            self.resultsDf[s] = self.resultsDf[s].fillna(0)\n",
    "        self.resultsDf['Latency_min'] = self.resultsDf['Latency_min'].fillna(120)\n",
    "        self.monitorMin = str(int(monitorWindow/60))+' min'\n",
    "        self.outputPrefix = self.outputFolder+self.monitorMin\n",
    "        if plotDiagonal:\n",
    "            PeriFeedDiagonal = locoPlotters.plotPeriFeedDiagonal(self, monitorWindow)\n",
    "        if plotContrast:\n",
    "            pairedSpeedPlots = locoPlotters.plotPairedSpeeds(self, monitorWindow)\n",
    "    \n",
    "#     show_doc(calculatePeriFeedSpeed)\n",
    "    \n",
    "    def plotStacked(self, endMin = 120, metricsToStack = ['Volume', 'Speed'], colorBy = 'Genotype',\n",
    "                    customPalette = None, figsize = None, dotratio = 20, dotbase = 5, plotNonFeeders = True,\n",
    "                    ylimPresets = None, showRasterYticks = False):\n",
    "        \"\"\"\n",
    "\n",
    "        Plots a raster of feeds stacked with a selection of other metrics in a ribbon\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        endMin : int, in min, default 120\n",
    "            the upper range of data to plot\n",
    "        metricsToStack : list, default ['Volume', 'Speed']\n",
    "            metrics to plot in ribbons under the raster\n",
    "        colorBy : str, default 'Genotype'\n",
    "            the data column to use for coloring the plots \n",
    "        customPalette : dict, default None\n",
    "            custom palette \n",
    "        figsize : list of two elements, default None\n",
    "            figure size in cm, e.g. [10, 10]\n",
    "        dotratio : int, default 20\n",
    "            scaling factor of dot to feed size\n",
    "        dotbase : int, default 5\n",
    "            constant component for dot to feed size conversion\n",
    "        plotNonFeeders : boolean, default True\n",
    "        ylimPresets : an array of two element arrays, default None\n",
    "            e.g. if there are 2 ribbon plots, ylimPresets can be [[0, 1], [1, 2]]\n",
    "        showRasterYticks : boolean, default False         \n",
    "            when True, leaves the yticklabels on the raster plot for chamberID\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        `stackedFig`:  the figure\n",
    "        `feeds_sorted` : the sorted feeds plotted \n",
    "        `colorBy` : the final groupings for the coloring\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "\n",
    "        if figsize == None:\n",
    "            figsize = [15*self.cm, (12+len(metricsToStack)*4)*self.cm]                    \n",
    "        feeds = self.feedsRevisedDf.loc[self.feedsRevisedDf['RelativeTime_s']<=endMin*60]\n",
    "        if plotNonFeeders:\n",
    "            nonFeeders = list(set(self.resultsDf.ChamberID.unique())-set(feeds.ChamberID.unique()))\n",
    "            nonFeederDf = self.resultsDf.loc[self.resultsDf['ChamberID'].isin(nonFeeders)][['ChamberID', 'Genotype', 'Temperature', 'Status']]\n",
    "            feeds = pd.merge(feeds, nonFeederDf, how = 'outer', on = ['ChamberID', 'Genotype', 'Temperature', 'Status'])\n",
    "            nonFeederindex = feeds.loc[feeds['AviFile'].isna()].index\n",
    "            feeds.iloc[nonFeederindex, list(feeds.columns).index('RelativeTime_s')] = endMin*60\n",
    "            feeds.iloc[nonFeederindex, list(feeds.columns).index('FeedVol_nl')] = 0\n",
    "        else:\n",
    "            feeds = feeds.loc[~feeds['AviFile'].isna()]\n",
    "        if type(colorBy) == list and len(colorBy)>1:\n",
    "            self.metaDataDf[''.join(colorBy)] = self.metaDataDf[colorBy].agg('-'.join, axis=1)\n",
    "            feeds[''.join(colorBy)] = feeds[colorBy].agg('-'.join, axis=1)\n",
    "            colorBy = ''.join(colorBy)\n",
    "        keys = self.metaDataDf[colorBy].unique()\n",
    "        shortkeys = [''] * len(keys)\n",
    "        for k in range(len(keys)):\n",
    "            if 'Red Light' in keys[k]:\n",
    "                shortkeys[k] = keys[k].replace('-Red Light', '')\n",
    "            elif 'Green Light' in keys[k]:\n",
    "                shortkeys[k] = keys[k].replace('-Green Light', '')\n",
    "        feeds_sorted = feeds.sort_values(by=[colorBy, 'RelativeTime_s'])\n",
    "        chord = feeds_sorted.ChamberID.reset_index(drop = True)\n",
    "        _, idx = np.unique(chord, return_index=True)\n",
    "        chamberLabels = chord[np.sort(idx)]\n",
    "        chord_catType = pd.CategoricalDtype(categories = chamberLabels, ordered = True)\n",
    "        feeds_sorted['ChamberID'] = feeds_sorted['ChamberID'].astype(chord_catType)\n",
    "        feeds_sorted['time'] = pd.to_datetime(feeds_sorted['RelativeTime_s'], unit='s')\n",
    "        idx = pd.date_range(feeds_sorted.iloc[0]['time'], feeds_sorted.iloc[-1]['time'], freq = 'ms')\n",
    "        metricDict = {'Volume': '_feedVol_pl', \n",
    "                      'Count': '_feedCount', \n",
    "                      'Duration': '_feedRevisedDuration_s',  \n",
    "                     'Speed': '_V', \n",
    "                     'Y': '_Y'}\n",
    "        metricYLabelsDict = {'Volume': 'Feed \\nVolume (pL)', \n",
    "                      'Count': 'Feed Count', \n",
    "                      'Duration': 'Feed \\nDuration (s)',  \n",
    "                     'Speed': 'Speed (mm/s)', \n",
    "                     'Y': 'Height (mm)'}\n",
    "        if customPalette == None:\n",
    "            palette = locoPlotters.espressoCreatePalette(keys)\n",
    "        else:\n",
    "            palette = customPalette\n",
    "        colorByKeys = {k: self.metaDataDf.loc[self.metaDataDf[colorBy] == k].index for k in keys}\n",
    "        stackedFig, stackedAxes = plt.subplots(nrows = len(metricsToStack)+3, ncols = 1, tight_layout = True)\n",
    "        gs = stackedAxes[1].get_gridspec()\n",
    "        \n",
    "        for ax in stackedAxes[0:3]:\n",
    "            ax.remove()\n",
    "        axbig = stackedFig.add_subplot(gs[0:3])\n",
    "#         axbig.set_ylabel('Fly ID', fontweight = 'semibold')\n",
    "        axbig.plot(feeds_sorted['RelativeTime_s'], feeds_sorted['ChamberID'], 'w.')\n",
    "        axbig.invert_yaxis()\n",
    "        axbig.spines['top'].set_visible(False)\n",
    "        axbig.spines['right'].set_visible(False)\n",
    "        axbig.set_xlim(-endMin*0.02, endMin*1.05)\n",
    "        for i in range(len(feeds_sorted.index)):\n",
    "            feed = feeds_sorted.iloc[i, :]\n",
    "            if feed['Valid']==True:\n",
    "                axbig.plot(feed['RelativeTime_s']/60, feed['ChamberID'], '.', \n",
    "                           color = palette[feed[colorBy]], \n",
    "                           markersize = dotbase+dotratio*feed['FeedVol_nl']/feeds_sorted['FeedVol_nl'].max())\n",
    "            else:\n",
    "                if plotNonFeeders:\n",
    "                    axbig.plot(feed['RelativeTime_s']/60, feed['ChamberID'], '.', \n",
    "                       color = 'w', markersize = dotbase)\n",
    "        for k in range(len(keys)):\n",
    "            lineIdx = feeds_sorted.loc[feeds_sorted[colorBy] == keys[k]]['ChamberID']\n",
    "            uniqueLineIdx = lineIdx.values.unique()\n",
    "#             plt.plot([-endMin*0.05, -endMin*0.05], [uniqueLineIdx[0], uniqueLineIdx[-1]], color = palette[keys[k]])\n",
    "            plt.text(-endMin*0.03, uniqueLineIdx[round(len(uniqueLineIdx)/2)], shortkeys[k], ha = 'right', \n",
    "                     color = palette[keys[k]], fontsize = 12, fontweight = 'semibold', verticalalignment = 'center')\n",
    "        keyDots =[ 0.05, 0.1, 0.2, 0.4]\n",
    "        keyDotsLabels =[i*1000 for i in keyDots]\n",
    "        height = np.array(axbig.get_ylim()).max()\n",
    "        keyDotsY =[height*0.15, height*0.10,height*0.05,0]\n",
    "        for i in range(len(keyDots)):\n",
    "            plt.plot(endMin*1.04, keyDotsY[i], '.', markersize = 5+dotratio*keyDots[i], c = 'k', alpha = 0.4)\n",
    "            plt.text(endMin*1.06, keyDotsY[i], str(\"%.0f\" % keyDotsLabels[i])+' pL', c = 'k', verticalalignment = 'center')\n",
    "        s = [lab.get_text().split('ber')[-1] for lab in axbig.get_yticklabels()]\n",
    "        axbig.tick_params(\n",
    "            axis='y',          # changes apply to the x-axis\n",
    "            which='both',      # both major and minor ticks are affected\n",
    "            left=False,      # ticks along the bottom edge are off\n",
    "            top=False)\n",
    "        countLogDfRange = self.countLogDf.loc[self.countLogDf.iloc[:, 0]<endMin*60]\n",
    "        def ribbonMetric(countLog, metric, colorBy, palette, colorByKeys, ax = None):\n",
    "            for k in range(len(keys)):\n",
    "                locoPlotters.plotBoundedLine(countLogDfRange.iloc[:, 0]/60, \n",
    "                                             countLogDfRange.filter(regex = metric).iloc[:, colorByKeys[keys[k]]], \n",
    "                                             ax = ax, c = palette[keys[k]],  resamplePeriod = '60s', label = shortkeys[k])\n",
    "        for [m, mm]  in enumerate(metricsToStack):\n",
    "            ribbonMetric(countLogDfRange,  metricDict[mm], colorBy = colorBy,palette = palette, colorByKeys = colorByKeys, \n",
    "                         ax = stackedAxes[m+3])\n",
    "            stackedAxes[m+3].set_ylabel(metricYLabelsDict[mm], fontweight = 'semibold')\n",
    "            if stackedAxes[m+3].get_legend():\n",
    "                stackedAxes[m+3].get_legend().remove()                \n",
    "            stackedAxes[m+3].set_xlim(-endMin*0.02, endMin*1.05)\n",
    "            stackedAxes[m+3].spines[[ 'top']].set_visible(False)\n",
    "            stackedAxes[m+3].spines[['right']].set_visible(False)\n",
    "#             stackedAxes[m+3].grid(None)\n",
    "            if ylimPresets:\n",
    "                stackedAxes[m+3].set_ylim(ylimPresets[m])            \n",
    "            else:\n",
    "                stackedAxes[m+3].set_ylim(0-stackedAxes[m+3].get_ylim()[1]*0.05, stackedAxes[m+3].get_ylim()[1])\n",
    "            if m !=len(metricsToStack)-1:\n",
    "                stackedAxes[m+3].set_xticklabels('')\n",
    "        stackedAxes[-1].set_xlabel('Time (min)', fontweight = 'semibold')\n",
    "        s = [lab.get_text().split('ber')[-1] for lab in axbig.get_yticklabels()]\n",
    "        if showRasterYticks:\n",
    "            axbig.set_yticklabels(s, fontsize = 5)\n",
    "        else: \n",
    "            axbig.set_yticklabels('')\n",
    "        axbig.set_xticklabels('')\n",
    "        stackedFig.set_size_inches(figsize[0], figsize[1])\n",
    "        stackedFig.suptitle('', x = 0.1, y = 0.96, horizontalalignment='left', \n",
    "                            verticalalignment='top', fontsize = 20, fontname=\"Inter\", fontweight = 'semibold')\n",
    "        locoUtilities.espressoSaveFig(\n",
    "            stackedFig, 'TimeAligned' + ''.join(metricsToStack), self.metaDataDf.Date[0], self.outputFolder)\n",
    "\n",
    "        return stackedFig, feeds_sorted, colorBy\n",
    "#     show_doc(plotStacked)\n",
    "    \n",
    "    def calculateFallEvents(self, nstd=4, windowsize=1000, ewm1=12, ewm2=26, ewm3=9):\n",
    "        \"\"\"\n",
    "\n",
    "        Detects fall events\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        nstd : int, default 4\n",
    "            parameter in macd analysis\n",
    "        windowsize : int, default 1000\n",
    "            window size in macd analysis\n",
    "        ewm1 : int, default 12\n",
    "            parameter in macd analysis\n",
    "        ewm2 : int, default 26\n",
    "            parameter in macd analysis\n",
    "        ewm3: int, default 9\n",
    "            parameter in macd analysis\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        `self.resultsDf`:  updated to include `falls`\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # added Jan 2022 to detect falls\n",
    "        print('Detecting Fall Events...')\n",
    "        falls, newCountLog = locoDataMunger.fallEvents(\n",
    "            self.countLogDf, nstd, windowsize, ewm1, ewm2, ewm3)\n",
    "        self.resultsDf['falls'] = np.nanmax(falls, axis=0)\n",
    "        self.countLogDf = newCountLog\n",
    "        print('Done')\n",
    "#     show_doc(calculateFallEvents) \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e031d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
